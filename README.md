# Web Crawling com Python

Utilizei:
- requests
- html, lxml

Neste exemplo o spider raspa dados da pagina 1 e 2 sanvando em csv e json.
#### Arquivo csv 
[![Arquivo csv](https://i.imgur.com/K56AXjk.png?1 "Arquivo csv")](https://imgur.com/K56AXjk "Arquivo csv")
#### Arquivo Json
[![Arquivo json](https://i.imgur.com/puy3686.png?1 "Arquivo json")](https://imgur.com/puy3686 "Arquivo json")

##### Para utilizar este exemplo: 
1.  git clone  https://github.com/lucasmpampanini/web_crawling_python.git
2. abra shell e na pasta do projeto rode 
	 $ python3 crawler.py crawling_1 imprime 
	 $ python3 crawler.py crawling_1  save_json
	 $ python3 crawler.py crawling_1  save_csv
	 * fa√ßa o mesmo para o crawling_2
